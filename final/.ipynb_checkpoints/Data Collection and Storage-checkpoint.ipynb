{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection and Storage --- Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Content**\n",
    "- The Data has been collected for the period 2012 to 2016 from \"weather underground\" website through an secret API key\n",
    "- The collected data is in JSON file format\n",
    "- All the collected JSON files are stored as CSV files for each individual city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To hide the API key, it has been stored in a variable and used for the following analysis\n",
    "import os\n",
    "malickfairoz_authkey = os.getenv('auth_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generating the dates for last 5 years from 2012 to 2016\n",
    "from datetime import timedelta, date\n",
    "period =[]\n",
    "def daterange(start_date, end_date):\n",
    "    for n in range(int ((end_date - start_date).days)+1):\n",
    "        yield start_date + timedelta(n)\n",
    "\n",
    "start_date = date(2012, 1, 1)\n",
    "end_date = date(2016, 12, 31)\n",
    "for single_date in daterange(start_date, end_date):\n",
    "    #print (single_date.strftime(\"%Y%m%d\"))\n",
    "    period.append(single_date.strftime(\"%Y%m%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Created two list to store values for state and city\n",
    "state_list = ['NY','FL','MA','CA','MN']\n",
    "city_list = ['New_York','Orlando','Boston','San_Francisco','Duluth']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Using the data from API key and date, \n",
    "# The weather report data is generated for every day from 2012 to 2016\n",
    "# One day's data is stored in one JSON file \n",
    "# Each JSON files are organized and stored in a folder hierarchy.\n",
    "# This program is created as a Method for code optimization\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import calendar\n",
    "def datagenerator(state, city):\n",
    "    counter=0\n",
    "    for x in range(len(period)):\n",
    "        url = (requests.get('http://api.wunderground.com/api/'+malickfairoz_authkey+'/history_'+period[x]+'/q/'+state+'/'+city+'.json').json())            \n",
    "        path = ('data/weather/'+state+'_'+city+'/'+period[x][:4]+'/'+calendar.month_name[int(period[x][4:6])]+'/day'+period[x][6:]+'/'+period[x]+'.json')\n",
    "        if not os.path.exists('data/weather/'+state+'_'+city):\n",
    "            os.makedirs('data/weather/'+state+'_'+city)\n",
    "        if not os.path.exists('data/weather/'+state+'_'+city+'/'+period[x][:4]):\n",
    "            os.makedirs('data/weather/'+state+'_'+city+'/'+period[x][:4])\n",
    "        if not os.path.exists('data/weather/'+state+'_'+city+'/'+period[x][:4]+'/'+calendar.month_name[int(period[x][4:6])]):\n",
    "            os.makedirs('data/weather/'+state+'_'+city+'/'+period[x][:4]+'/'+calendar.month_name[int(period[x][4:6])])\n",
    "        if not os.path.exists('data/weather/'+state+'_'+city+'/'+period[x][:4]+'/'+calendar.month_name[int(period[x][4:6])]+'/day'+period[x][6:]):\n",
    "            os.makedirs('data/weather/'+state+'_'+city+'/'+period[x][:4]+'/'+calendar.month_name[int(period[x][4:6])]+'/day'+period[x][6:])\n",
    "        if os.path.exists('data/weather/'+state+'_'+city+'/'+period[x][:4]+'/'+calendar.month_name[int(period[x][4:6])]+'/day'+period[x][6:]):\n",
    "            with open(path, 'w') as outfile:\n",
    "                json.dump(url, outfile)\n",
    "            with open(path) as json_data:\n",
    "                temp = json.load(json_data)\n",
    "            open(path, \"w\").write(\n",
    "                json.dumps(temp['history']['dailysummary'], sort_keys=True, indent=4, separators=(',', ': ')))\n",
    "            counter +=1 \n",
    "\n",
    "    print(repr(counter) + \" Json files dumped in folder for \" + state+'_'+city)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1827 Json files dumped in folder for NY_New_York\n"
     ]
    }
   ],
   "source": [
    "# Getting data for the city New_York, NY\n",
    "datagenerator(state_list[0], city_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1827 Json files dumped in folder for FL_Orlando\n"
     ]
    }
   ],
   "source": [
    "# Getting data for the city Orlando, FL\n",
    "datagenerator(state_list[1], city_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1827 Json files dumped in folder for MA_Boston\n"
     ]
    }
   ],
   "source": [
    "# Getting data for the city Boston, MA\n",
    "datagenerator(state_list[2], city_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1827 Json files dumped in folder for CA_San_Francisco\n"
     ]
    }
   ],
   "source": [
    "# Getting data for the city San_Francisco, CA\n",
    "datagenerator(state_list[3], city_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1827 Json files dumped in folder for MN_Duluth\n"
     ]
    }
   ],
   "source": [
    "# Getting data for the city Duluth, MN\n",
    "datagenerator(state_list[4], city_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# the JSON files and scanned through folders and stored in a CSV file \n",
    "# Each JSON file will be stored as a record in a CSV file\n",
    "# For each city one CSV file is created with data and stored in folder hierarchy\n",
    "# This program is created as a Method for code optimization\n",
    "import sys\n",
    "import glob\n",
    "import csv\n",
    "def datawriter(state, city):\n",
    "    if not os.path.exists('data/weather_csvfiles/'):\n",
    "        os.makedirs('data/weather_csvfiles/')\n",
    "    count = 0\n",
    "    emptycsv = open(r'data/weather_csvfiles/'+city+'.csv', 'w',newline='')\n",
    "    emptycsvwriter = csv.writer(emptycsv)\n",
    "    basepath1 = 'data/weather/'+state+'_'+city\n",
    "    if os.path.isdir(basepath1):\n",
    "        for name1 in os.listdir(basepath1)[:]:\n",
    "            basepath2 = os.path.join(basepath1, name1)\n",
    "            if os.path.isdir(basepath2):\n",
    "                for name2 in os.listdir(basepath2)[:]:\n",
    "                    basepath3 = os.path.join(basepath2, name2)\n",
    "                    if os.path.isdir(basepath3):\n",
    "                        for name3 in os.listdir(basepath3)[:]:\n",
    "                            basepath4 = os.path.join(basepath3, name3)\n",
    "                            if os.path.isdir(basepath4):\n",
    "                                for name4 in os.listdir(basepath4)[:]:\n",
    "                                    basepath5 = os.path.join(basepath4, name4)\n",
    "                                    files = glob.glob(basepath5)   \n",
    "                                    for jsondata in files:\n",
    "                                        items = open(jsondata).read()\n",
    "                                        items_data = json.loads(items)\n",
    "                                        items_data_output = open(r'data/weather_csvfiles/'+city+'.csv', 'a',newline='')\n",
    "                                        csvwriter = csv.writer(items_data_output)\n",
    "                                        for rowdata in items_data:\n",
    "                                            rowdataconcat = {**rowdata,**rowdata['date']}\n",
    "                                            if count == 0:\n",
    "                                                header = rowdataconcat.keys()\n",
    "                                                csvwriter.writerow(header)\n",
    "                                                count += 1\n",
    "                                            csvwriter.writerow(rowdataconcat.values())\n",
    "                                        items_data_output.close()\n",
    "    emptycsv.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# writing data to CSV for the city New_York, NY\n",
    "datawriter(state_list[0], city_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writing data to CSV for the city Orlando, FL\n",
    "datawriter(state_list[1], city_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writing data to CSV for the city Boston, MA\n",
    "datawriter(state_list[2], city_list[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writing data to CSV for the city San_Francisco, CA\n",
    "datawriter(state_list[3], city_list[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# writing data to CSV for the city Duluth, MN\n",
    "datawriter(state_list[4], city_list[4])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
