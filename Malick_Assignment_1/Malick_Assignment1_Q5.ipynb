{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "- Use Gutenberg and Web_text data. Find out what are the top 5 words that Shakespeare used but we do not use in currently.\n",
    "- Take top 50 words from Shakespeare (all 3 books) and top 50 from Web_text (all the records).\n",
    "- Remove punctuation and stop words.\n",
    "- Remove the words we still use today, and get the unused list. Show the top 5 elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Importing nltk\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stored the list of books from gutenberg package in 'gutenberg_file'\n",
    "gutenberg_file = nltk.corpus.gutenberg.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#stored the list of books from webtext package in 'webtext_file'\n",
    "webtext_file = nltk.corpus.webtext.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86333\n"
     ]
    }
   ],
   "source": [
    "#Gathering words from all three shakespeare books and stored in 'total_shakes'\n",
    "total_shakes1 = nltk.corpus.gutenberg.words('shakespeare-caesar.txt')\n",
    "total_shakes2 = nltk.corpus.gutenberg.words('shakespeare-hamlet.txt')\n",
    "total_shakes3 = nltk.corpus.gutenberg.words('shakespeare-macbeth.txt')\n",
    "total_shakes = total_shakes1 + total_shakes2 + total_shakes3\n",
    "print(len(total_shakes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#First converting the totall words into normal list through itertool and stored in 'wordlist_shakes'\n",
    "import itertools\n",
    "l = [([x] if isinstance(x,str) else x) for x in total_shakes]\n",
    "wordlist_shakes = list(itertools.chain(*l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "396733\n"
     ]
    }
   ],
   "source": [
    "#Gathering words from all books and stored in 'total_webtext'\n",
    "total_webtext = nltk.corpus.webtext.words()\n",
    "print(len(total_webtext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#First converting the totall words into normal list through itertool and stored in 'wordlist_webtext'\n",
    "import itertools\n",
    "l1 = [([x] if isinstance(x,str) else x) for x in total_webtext]\n",
    "wordlist_webtext = list(itertools.chain(*l1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#To get the all unused wordlist which is used in shakespeare and not used currently web_text\n",
    "unused_wordlist = []\n",
    "unused_wordfreq = []\n",
    "for w in wordlist_shakes:\n",
    "    if w not in wordlist_webtext:\n",
    "        unused_wordfreq.append(wordlist_shakes.count(w))\n",
    "        unused_wordlist.append(w)\n",
    "fullunused =dict(zip(unused_wordlist, unused_wordfreq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sorting the dictionery 'fullunused' by high frequency words used and stores in 'sorted_fullunused'\n",
    "import operator\n",
    "sorted_fullunused = sorted(fullunused.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'selfe': 139, 'haue': 406, 'Brutus': 162, 'Ham': 337, 'Bru': 153}\n"
     ]
    }
   ],
   "source": [
    "#To get top 5 words from the sorted dictionery \"sorted_fullunused\" and diplayed \"sorted_fullunused_top5\"\n",
    "limit=0\n",
    "sorted_fullunused_top5 = {}\n",
    "for k in sorted_fullunused:\n",
    "    limit+=1\n",
    "    if limit<6:\n",
    "         sorted_fullunused_top5.update({k})\n",
    "print(sorted_fullunused_top5) # ANSWER for Step 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the top 50 words from 3 - Shakespeare books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing the stop words from nltk and also addition some punctuation to the same list \"stopwordlist\"\n",
    "stopwordlist = []\n",
    "punctuation = [\";\",\"'\",\"?\",\":\",\"-\",\",\",\".\"]\n",
    "from nltk.corpus import stopwords\n",
    "stopwordlist = stopwords.words('english')\n",
    "stopwordlist = stopwordlist + punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Removing the stop words and punctuation from \"wordlist_shakes\"\n",
    "wordlist_shakes_nostopwords = []\n",
    "for k in wordlist_shakes:\n",
    "    if k not in stopwordlist:\n",
    "        wordlist_shakes_nostopwords.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Getting all the words and its used frequency and stored them in a dictionery \"shakes_top50\"\n",
    "shakes_top50 = {}\n",
    "shakes_wordlist = []\n",
    "shakes_wordfreq = []\n",
    "for w in wordlist_shakes_nostopwords:\n",
    "    shakes_wordfreq.append(wordlist_shakes.count(w))\n",
    "    shakes_wordlist.append(w)\n",
    "shakes_top50 =dict(zip(shakes_wordlist, shakes_wordfreq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sorting the dictionery 'shakes_top50' by high frequency words and stores in 'sorted_shakes_top50'\n",
    "import operator\n",
    "sorted_shakes_top50 = sorted(shakes_top50.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'My': 121, 'As': 130, 'Enter': 225, 'man': 132, 'thou': 256, 'Why': 107, 'He': 126, 'th': 108, 'vs': 183, 'vpon': 126, 'come': 151, 'Cassi': 107, 'Ile': 106, 'What': 239, 'say': 113, 'You': 119, 'A': 116, 'good': 165, 'It': 120, 'st': 110, 'King': 231, 'haue': 406, 'selfe': 139, 'Bru': 153, 'And': 645, 'For': 164, 'Ham': 337, 'like': 142, 'must': 116, 'If': 132, 'I': 1417, 'Caesar': 192, 'let': 122, 'That': 289, 'thy': 175, 'thee': 174, 'well': 126, 'shall': 259, 'The': 327, 'O': 122, 'But': 236, 'Brutus': 162, 'hath': 115, 'To': 258, 'know': 169, 'see': 104, 'would': 142, 'Macb': 137, 'may': 121, 'Lord': 293}\n"
     ]
    }
   ],
   "source": [
    "#To get top 50 words from the sorted dictionery \"sorted_shakes_top50\" and diplayed \"sorted_shakes_top50_output\"\n",
    "limit=0\n",
    "sorted_shakes_top50_output = {}\n",
    "for k in sorted_shakes_top50:\n",
    "    limit+=1\n",
    "    if limit<51:\n",
    "        sorted_shakes_top50_output.update({k})\n",
    "print(sorted_shakes_top50_output) # ANSWER for Step 2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting top 50 words from all books of WEB_TEXT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Removing the stop words and punctuation from \"wordlist_shakes\"\n",
    "wordlist_webtext_nostopwords = []\n",
    "for k in wordlist_webtext:\n",
    "    if k not in stopwordlist:\n",
    "        wordlist_webtext_nostopwords.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Getting all the words and its used frequency and stored them in a dictionery \"webtext_top50\"\n",
    "webtext_top50 = {}\n",
    "webtext_wordlist = []\n",
    "webtext_wordfreq = []\n",
    "for w in wordlist_webtext_nostopwords:\n",
    "    webtext_wordfreq.append(wordlist_webtext.count(w))\n",
    "    webtext_wordlist.append(w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Making the 'webtext_wordlist' as key and 'webtext_wordfreq' as value for the dictionery \"webtext_top50\"\n",
    "webtext_top50 =dict(zip(webtext_wordlist, webtext_wordfreq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sorting the dictionery 'webtext_top50' by high frequency words and stores in 'sorted_webtext_top50'\n",
    "import operator\n",
    "sorted_webtext_top50 = sorted(webtext_top50.items(), key=operator.itemgetter(1), reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'My': 121, 'As': 130, 'Enter': 225, 'man': 132, 'thou': 256, 'Why': 107, 'He': 126, 'th': 108, 'vs': 183, 'vpon': 126, 'come': 151, 'Cassi': 107, 'Ile': 106, 'What': 239, 'say': 113, 'You': 119, 'A': 116, 'good': 165, 'It': 120, 'st': 110, 'King': 231, 'haue': 406, 'selfe': 139, 'Bru': 153, 'And': 645, 'For': 164, 'Ham': 337, 'like': 142, 'must': 116, 'If': 132, 'I': 1417, 'Caesar': 192, 'let': 122, 'That': 289, 'thy': 175, 'thee': 174, 'well': 126, 'shall': 259, 'The': 327, 'O': 122, 'But': 236, 'Brutus': 162, 'hath': 115, 'To': 258, 'know': 169, 'see': 104, 'would': 142, 'Macb': 137, 'may': 121, 'Lord': 293}\n"
     ]
    }
   ],
   "source": [
    "#To get top 50 words from the sorted dictionery \"sorted_webtext_top50\" and diplayed \"sorted_webtext_top50_output\"\n",
    "limit=0\n",
    "sorted_webtext_top50_output = {}\n",
    "for k in sorted_shakes_top50:\n",
    "    limit+=1\n",
    "    if limit<51:\n",
    "        sorted_webtext_top50_output.update({k})\n",
    "print(sorted_webtext_top50_output) # ANSWER for Step 2b"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
